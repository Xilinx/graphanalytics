{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c450662e",
   "metadata": {},
   "source": [
    "# Welcome to Xilinx Cosine Similarity Acceleration Demo \n",
    "---\n",
    "\n",
    "**This Notebook demonstrates how to use the Xilinx Cosine Similarity product and shows the power of Xilinx FPGAs to accelerate Cosine Similarity**\n",
    "\n",
    "---\n",
    "\n",
    "### The Demo : Log Similarity \n",
    "\n",
    "This example uses Tigergraph Graph database to represent Log messages within their contexts and finds similar trouble Logs messages for a given query Message. \n",
    "\n",
    "Hence, in turn, a user can apply the solution(s) provided in the past, to resolve current issues. <br><br>\n",
    "\n",
    "The User can provide a <u>Message string</u> to search for similar trouble Logs occurred in the past.\n",
    "\n",
    "This Example selects a random vertex in the graph as the query and filters out the Log Database and returns the Top Matching Logs. \n",
    "\n",
    "The Top Matching are calculated based on similarity between the given Message against all the Log entries.\n",
    "The Match similarity used here is [Cosine Similarity](https://en.wikipedia.org/wiki/Cosine_similarity)\n",
    "\n",
    "Instead of finding Similarity with the direct one-hot word representation, we used [GloVe](https://en.wikipedia.org/wiki/GloVe_(machine_learning)) Word Embeddings, which maps words into more meaningful space.\n",
    "\n",
    "In General, finding Cosine Similarity on large dataset will take a huge amount of time on CPU \n",
    "\n",
    "With the Xilinx Cosine Similarity Acceleration, it can speedup the process by multiple orders.\n",
    "\n",
    "We will use the Xilinx Cosine Similarity in the backend and setup a Log Database against which similarity of target vectors can be calculated.\n",
    "\n",
    " \n",
    "### The Demo is Structured into Seven Sections :\n",
    "\n",
    "1. [**Create New Graph**](#newg)\n",
    "<br><br>\n",
    "2. [**Create Graph Schema**](#schema)\n",
    "<br><br>\n",
    "3. [**Load Graph Data**](#loadd)\n",
    "<br><br>\n",
    "4. [**Install Queries**](#install)\n",
    "<br><br>\n",
    "5. [**Create Embeddings**](#embed)\n",
    "<br><br>\n",
    "6. [**Send Embeddings to FPGA**](#send)\n",
    "<br><br>\n",
    "7. [**Compute Cosine Similarity**](#run)\n",
    "\n",
    "---\n",
    "Steps [ 1 - 6 ] are **One-Time** preparation of the Database. \n",
    "\n",
    "Step [ 7 ] is **Repeatable** use of Query to run *accelerated* similarity computation on FPGA \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17b6f37",
   "metadata": {},
   "source": [
    "### Prerequisites <a id=\"prerequisites\"></a> :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a906435",
   "metadata": {},
   "source": [
    "#### Load Necessary Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea18ce21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random as rand\n",
    "from pathlib import Path, PurePosixPath\n",
    "import pyTigerGraph as tg\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78003dbd",
   "metadata": {},
   "source": [
    "#### Check the Python version. It should be 3.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b640548",
   "metadata": {},
   "outputs": [],
   "source": [
    "from platform import python_version\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b35f43",
   "metadata": {},
   "source": [
    "#### Provide the Host Name, User Name & Password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fac957e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hostName = \"localhost\"                            # TG server hostname\n",
    "userName = \"tigergraph\"                           # TG user name\n",
    "passWord = \"tigergraph\"                           # TG password"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a053bf11",
   "metadata": {},
   "source": [
    "#### Provide the number of results 'topK' to find & Number of U50 Cards installed on System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280135d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "topK = 10                                         # Number of highest scoring log record matches\n",
    "numDevices = 1                                    # Number of FPGA devices to distribute the queries to"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3e9a51",
   "metadata": {},
   "source": [
    "#### Path Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7755987f",
   "metadata": {},
   "source": [
    "**Local**: Location of query files under the Xilinx graphanalytics github repo. Set location of the local repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8aeff0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "localRepoLocation = Path(\"/proj/xsjhdstaff3/sachink/ghe\")\n",
    "exampleLocation = Path(\"graphanalytics/plugin/tigergraph/recomengine/staging/examples/log_similarity\") # when running from github repo\n",
    "queryFileLocation = localRepoLocation / exampleLocation / \"query\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845e890e",
   "metadata": {},
   "source": [
    "**Remote**: Location of synthea generated data on the server. NOTE: Data should exist on the TigerGraph server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331275af",
   "metadata": {},
   "outputs": [],
   "source": [
    "serverRepoLocation = PurePosixPath(\"/proj/xsjhdstaff3/sachink/ghe\")\n",
    "serverDataLocation = serverRepoLocation / PurePosixPath(exampleLocation) / \"data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d3dd9e",
   "metadata": {},
   "source": [
    "#### Download the GloVe File  <a id=\"DownloadFiles\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874a670d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(\"/tmp/glove.6B.50d.txt\") :\n",
    "    if not os.path.isfile(\"/tmp/glove.6B.50d.txt.tar\") :\n",
    "        print(\"Dowloading GloVe Embedding File ...\")\n",
    "        os.chdir(\"/tmp\")\n",
    "        os.system(\"wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1ogyMmAu0fcZBdSwTQJuX6jHLzlTJnql0' -O glove.6B.50d.txt.tar\")\n",
    "        print(\"Download Completed!\")\n",
    "    print(\"Extracting GloVe Embedding File ...\")\n",
    "    os.chdir(\"/tmp\")\n",
    "    os.system(\"tar -xvzf glove.6B.50d.txt.tar\")\n",
    "    print(\"Done!\")\n",
    "else:\n",
    "    print(\"GloVe Model File already present.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb882bc1",
   "metadata": {},
   "source": [
    "---\n",
    "### 1. Create New Graph <a id=\"newg\"></a>\n",
    "- Connect to TigerGraph server by ommiting graph name. This is needed to establish a valid REST endpoint that will be used to create a new desired graph\n",
    "- Create new graph by using gsql command and create a new connection with the new graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0bb816",
   "metadata": {},
   "outputs": [],
   "source": [
    "graphName = f'xgraph_logsim_{userName}'\n",
    "conn = tg.TigerGraphConnection(host='http://' + hostName, graphname='', username=userName, password=passWord, useCert=False)\n",
    "print(\"\\n--------- Creating New graph ----------\")\n",
    "print(conn.gsql(f'create graph {graphName}()', options=[]))\n",
    "\n",
    "# connect to TG server with new graph\n",
    "print(f'Using graph {graphName}')\n",
    "conn = tg.TigerGraphConnection(host='http://' + hostName, graphname=graphName, username=userName, password=passWord, useCert=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82819e55",
   "metadata": {},
   "source": [
    "### 2. Create Graph Schema <a id=\"schema\"></a>\n",
    "TigerGraph stores graph in the form of vertices that can be associated with other vertices using directed or undirected edges. This is specified in the form of a graph schema. For the purpose of this demo, the schema is already defined as a query file. Load the file, set graph name and run it as gsql commands. \n",
    "\n",
    "The user can create schema for their own graph in a similar way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dfafb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"\\n--------- Creating New Schema ----------\")\n",
    "schemaFile = queryFileLocation / \"schema_xgraph.gsql\"\n",
    "\n",
    "with open(schemaFile) as fh:\n",
    "    qStrRaw = fh.read()\n",
    "    qStr = qStrRaw.replace('@graph', graphName)\n",
    "    print(conn.gsql(qStr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c7cb7e",
   "metadata": {},
   "source": [
    "### 3. Load Graph Data <a id=\"loadd\"></a>\n",
    "The Log dataset is split into files for each vertex and edge. Each file is loaded and parsed to populate vertex attributes and edges. Open the load query file and, set graph name and location of the data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bdcec0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"\\n--------- Loading data into graph ----------\")\n",
    "loadFile = queryFileLocation / \"load_xgraph.gsql\"\n",
    "\n",
    "with open(loadFile) as fh:\n",
    "    qStrRaw = fh.read()\n",
    "    qStrRaw = qStrRaw.replace('@graph', graphName)\n",
    "    qStr    = qStrRaw.replace('$sys.data_root', str(serverDataLocation))\n",
    "    print(conn.gsql(qStr))\n",
    "    print(conn.gsql(f\"USE GRAPH {graphName}\\n RUN LOADING JOB load_xgraph\"))\n",
    "    print(conn.gsql(f\"USE GRAPH {graphName}\\n DROP JOB load_xgraph\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fa3074",
   "metadata": {},
   "source": [
    "### 4. Install Queries <a id=\"install\"></a>\n",
    "The cosine similarity application functionality is implemented using gsql queries and UDF functions. The queries need to be installed before running.\n",
    "\n",
    "The user can create their own queries and install them instead. If user writes their own UDFs, they will need to be compilled and opened as a TigerGraph Plugin (this is not covered in the scope of this demo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3a562b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--------- Installing Queries ----------\")\n",
    "baseQFile = queryFileLocation / \"base.gsql\"\n",
    "clientQFile = queryFileLocation / \"client.gsql\"\n",
    "\n",
    "with open(baseQFile) as bfh, open(clientQFile) as cfh:\n",
    "    print(\"installing base queries ...\")\n",
    "    qStrRaw = bfh.read()\n",
    "    qStr = qStrRaw.replace('@graph', graphName)\n",
    "    print(conn.gsql(qStr))\n",
    "    \n",
    "    print(\"\\ninstalling client queries ...\")\n",
    "    qStrRaw = cfh.read()\n",
    "    qStr = qStrRaw.replace('@graph', graphName)\n",
    "    print(conn.gsql(qStr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9210af54",
   "metadata": {},
   "source": [
    "Now that queries are installed, rest of the operations can be performed simply by running the queries as follows.\n",
    "\n",
    "### 5. Create Embeddings <a id=\"embed\"></a>\n",
    "---\n",
    "As seen earlier in the schema, each Log Record has a set of attributes and is represented as a vertex. The attributes of Log Records are embedded into vector representation called embeddings which are then stored as part of the Log Record vertices themselves. \n",
    "\n",
    "To create embeddings, we use Global Vector word representations and simply take average of embeddings of words occuring in a Log Record. Users are encouraged to experiment with different ways of computing the embeddings and optimize the quality of similarity results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1bc38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Creating Log embeddings and storing them in LogRecord vertices...')\n",
    "tStart = time.perf_counter()\n",
    "conn.runInstalledQuery('client_cosinesim_embed_vectors', timeout=240000000)\n",
    "conn.runInstalledQuery('client_cosinesim_embed_normals', timeout=240000000)\n",
    "print(f'completed in {time.perf_counter() - tStart:.4f} sec')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856ce108",
   "metadata": {},
   "source": [
    "### 6. Send embeddings to FPGA <a id=\"send\"></a>\n",
    "---\n",
    "Finally, the embeddings are collected in a buffer which is sent/copied to HBM memory on the FPGA device. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b99c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading data into FPGA memory...')\n",
    "# set number of FPGAs to use\n",
    "conn.runInstalledQuery('client_cosinesim_set_num_devices', {'numDevices': numDevices}, timeout=240000000)\n",
    "\n",
    "# distribute data to FPGA memory\n",
    "tStart = time.perf_counter()\n",
    "resultHwLoad = conn.runInstalledQuery('client_cosinesim_load_alveo', timeout=240000000)\n",
    "print(f'completed in {time.perf_counter() - tStart:.4f} sec\\n')\n",
    "\n",
    "# Check status\n",
    "status = conn.runInstalledQuery('client_cosinesim_get_alveo_status', timeout=240000000)\n",
    "isInit = status[0][\"IsInitialized\"]\n",
    "numDev = status[0][\"NumDevices\"]\n",
    "print(f'FPGA Init: {isInit}, Dev: {numDev}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56874b06",
   "metadata": {},
   "source": [
    "#### Definitions to get Log Record and Print the TopK Matchings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf123d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRecord(id):\n",
    "    recordList = conn.getVerticesById('LogRecord', id)\n",
    "    return [] if len(recordList) == 0 else recordList[0]\n",
    "\n",
    "def printResults(result, newRecord):\n",
    "    matches = result[0]['Matches']\n",
    "    print(f\"Matches for Record: {newRecord['v_id']} {newRecord['attributes']['SEVERITY']} {newRecord['attributes']['MESSAGE']}\\n\")\n",
    "    print(\"RANK     ID        SEVERITY       MESSAGE\" + 50*\" \" + \"Confidence\")\n",
    "    print(\"----|---------|---------------|\" + 60*\"-\" + \"|------------\")\n",
    "    i = 0\n",
    "    for m in matches:\n",
    "        matchingRecord = getRecord(m['Id'])\n",
    "        print(f\" {i+1:02d}  {m['Id']:10}  {matchingRecord['attributes']['SEVERITY']:13} {matchingRecord['attributes']['MESSAGE'][:55]:60} {m['score']:.6f}\")\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d447f809",
   "metadata": {},
   "source": [
    "This completes the TigerGraph database and consine similiarity compute preparation. We can now run as many similarity queries as we want. \n",
    "\n",
    "### 7. Compute Cosine Similarity <a id=\"run\"></a>\n",
    "---\n",
    "For the purpose of this demo, we get the first 100 Log Records and choose one at random. Log Records are represented by an ID which is passed to the match query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f803a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Running Query...')\n",
    "# pick a random log record out of 100\n",
    "targetLogRecords = conn.getVertices('LogRecord', limit=100)\n",
    "targetLogRecord = targetLogRecords[rand.randint(0,99)]\n",
    "\n",
    "# run similarity on the choosen log record\n",
    "tStart = time.perf_counter()\n",
    "result = conn.runInstalledQuery('client_cosinesim_match_alveo',\n",
    "                                  {'queryRecord': targetLogRecord['v_id'], 'topK': topK}, timeout=240000000)\n",
    "tDuration = 1000*(time.perf_counter() - tStart)\n",
    "\n",
    "printResults(result, targetLogRecord)\n",
    "resTime = result[0][\"ExecTimeInMs\"]\n",
    "print(f\"\\nRound Trip time: {tDuration:.2f} msec\")\n",
    "print(f\"     Query time: {resTime:.2f} msec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bd437e",
   "metadata": {},
   "source": [
    "Notice that as a sanity check, one of the top matching records is the query Log Record itself with a match score of 1.\n",
    "Feel free to play with the query!\n",
    "\n",
    "#### Thanks for your time!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
