/*
 * Copyright 2020 Xilinx, Inc.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WANCUNCUANTIES ONCU CONDITIONS OF ANY KIND, either express or
 * implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

USE GRAPH @graph
DROP QUERY louvain_alveo, close_alveo, tg_partition_phase_1, tg_partition_phase_2, tg_partition_phase_3



CREATE DISTRIBUTED QUERY tg_partition_phase_1(
    SET<STRING> v_types,            // List of vertex types that would participate in Louvain Modularity
    SET<STRING> e_types,            // List of edge types that would participate in Louvain Modularity
    STRING weight_attr,             // Name of the edge attribute that has weight of the edge
    STRING louvainId_attr
) FOR GRAPH @graph
{
    //ListAccum<UINT> @@nodeAccum;
    SumAccum<UINT> @@total_out_degree;

    Start = {v_types};
    nodes = {dummy_nodes.*};

    nodeList = SELECT n FROM nodes:n
        ACCUM udf_xilinx_comdetect_set_node_id(n.NODE_ID), udf_reset_nextId();

    A1 = SELECT n FROM Start:n
        // Local to each server, louvainid is local increasing id
        ACCUM @@total_out_degree+=n.outdegree()
        POST-ACCUM n.setAttr(louvainId_attr, udf_get_nextId(n.outdegree()))
        ORDER BY n.louvainId;
            
    PRINT @@total_out_degree;
}

CREATE DISTRIBUTED QUERY tg_partition_phase_2(
    SET<STRING> v_types,            // List of vertex types that would participate in Louvain Modularity
    SET<STRING> e_types,            // List of edge types that would participate in Louvain Modularity
    STRING weight_attr,             // Name of the edge attribute that has weight of the edge
    STRING louvainId_attr
) FOR GRAPH @graph
{
    SumAccum<UINT> @globalId;
    
    MapAccum<UINT,UINT> @@parSize; //nodeid-> parSize
    MapAccum<UINT,UINT> @@offsets; //nodeid -> offsets
    
    Start = {v_types};
    nodes = {dummy_nodes.*};
    @@offsets += (0 -> 0);
  
    partitionSizeList = SELECT n FROM nodes:n
        ACCUM @@parSize += (n.NODE_ID -> udf_get_partition_size() );
    
    PRINT @@parSize;

    FOREACH n IN RANGE[0,nodes.size()-1] DO
        @@offsets += (n+1 -> @@offsets.get(n)+@@parSize.get(n));
    END;

    offsetList = SELECT n FROM nodes:n
        ACCUM udf_set_louvain_offset(@@offsets.get(n.NODE_ID));

    PRINT @@offsets;
    
    //assign global id
    louvainGlobal = SELECT s FROM Start:s
        ACCUM s.@globalId = udf_get_global_louvain_id(s.getAttr(louvainId_attr,"UINT"))
        POST-ACCUM s.setAttr(louvainId_attr ,s.@globalId);
        //POST-ACCUM s.setAttr(louvainId_attr , udf_get_global_louvain_id(s.getAttr(louvainId_attr,"UINT")));
    
}

CREATE DISTRIBUTED QUERY tg_partition_phase_3(
    SET<STRING> v_types,            // List of vertex types that would participate in Louvain Modularity
    SET<STRING> e_types,            // List of edge types that would participate in Louvain Modularity
    STRING weight_attr,             // Name of the edge attribute that has weight of the edge
    STRING louvainId_attr,
    UINT numPar = 1
) FOR GRAPH @graph 
{
    STRING gName = "@graph" ;
    MapAccum<UINT,INT> @@nodeAccum;
    
    print gName;

    udf_reset_timer(true);
    Start = {v_types};
    nodes = {dummy_nodes.*}; 
 
    udf_reset_timer(true);
    tmpList = SELECT n FROM nodes:n
       ACCUM udf_save_EdgePtr();
    
    vertexList = SELECT s FROM Start:s-(e_types:e)->:t
        ACCUM udf_set_louvain_edge_list(s.louvainId, t.louvainId, e.getAttr(weight_attr,"FLOAT"), t.outdegree());    
    PRINT udf_elapsed_time(true) AS SetLouvainEdgeListTime;
    
    udf_reset_timer(true);
    nodeList = SELECT n FROM nodes:n 
        ACCUM udf_start_partition(gName, Start.size());
    PRINT udf_elapsed_time(true) AS StartPartitionTime;
       
    udf_reset_timer(true);
    parList = SELECT n FROM nodes:n
        ACCUM @@nodeAccum += (n.NODE_ID -> udf_save_alveo_partition(numPar));
    PRINT @@nodeAccum;
    PRINT udf_elapsed_time(true) AS SaveAlveoPartitionTime;

    udf_reset_timer(true);
    nodeList = SELECT n FROM nodes:n
        ACCUM udf_finish_partition(@@nodeAccum);
    PRINT udf_elapsed_time(true) AS FinishPartitionTime;
  
}



CREATE DISTRIBUTED QUERY louvain_alveo(
    SET<STRING> v_type,             // Set of names of vertex types to be considered. Example: ["Person", "Animal"]
    SET<STRING> e_type,             // Set of names of edge types to be considered. Example: ["co-worker", "owner"]
    STRING wt_attr,                 // Name of the edge attribute which has weight of the edge. Example: "weight"
    INT max_iter = 10,              // Maximum number of iterations for moving nodes and evaluating Q for a level
    INT max_level = 10,             // Maximum number of levels or passes of condensing communities and reapplying louvain
    FLOAT tolerence = 0.00001,      // Maximum delta Q that is considered no change
    BOOL intermediateResult = TRUE, // Store intermediate results such as intermediate community in the 'result_file'
    BOOL verbose = FALSE,           // Print debugging messages
    STRING result_attr = "",        // Name of the attribute of a vertex to store the final community Id in
    STRING result_file = "",        // Full path of result file. It must be accessible on each machine in cluster.
    BOOL print_final_Q = TRUE,      // Print final Q value
    BOOL print_all_Q = FALSE)       // Print intermediate Q value
{
    ListAccum<int> @@nodeAccum;
    ListAccum<float> @@modularityAccum;
    DOUBLE udf_time;
    DOUBLE vm_peak, vm_hwm;
    INT ret;
    STRING gName = "@graph" ;
    nodes = {dummy_nodes.*};
    nodeList = SELECT n FROM nodes:n
        ACCUM @@nodeAccum += udf_xilinx_comdetect_set_node_id(n.NODE_ID);

    udf_reset_timer(true);
    udf_execute_reset(0);

    // each node will get this UDF call for each vertex, but the actual execution
    // is only run once guarded by a flag. Each node checks if it's master or slave
    // and run the task accordingly.

    nodelist = SELECT n FROM nodes:n
           ACCUM @@modularityAccum += udf_louvain_alveo(gName,
           max_iter, max_level, tolerence, intermediateResult,
           verbose, result_file, print_final_Q, print_all_Q);

    udf_time = udf_elapsed_time(true);
    ret = udf_peak_memory_usage(vm_peak, vm_hwm);
    print nodes.size() as NumOfNodes;
    print @@modularityAccum as ModularityQValues;
    print "Xilinx Alveo U50" AS ComputationTechnique;
    print vm_peak/1000000.0 as PeakVirtualMemoryInGB;
    print vm_hwm/1000000.0 as PeakResidentMemoryInGB;
    print udf_time as ExecTimeInMs;
}

CREATE DISTRIBUTED QUERY close_alveo() for GRAPH @graph {
   DOUBLE udf_time;
   BOOL b;
   //udf_reset_timer(true);
   Start = {Person.*};
   A = SELECT v
       FROM Start:v
       ACCUM udf_close_alveo(1);
   //udf_time = udf_elapsed_time(true);
   //print udf_time, b;
}

install query close_alveo, louvain_alveo, tg_partition_phase_1, tg_partition_phase_2,tg_partition_phase_3
