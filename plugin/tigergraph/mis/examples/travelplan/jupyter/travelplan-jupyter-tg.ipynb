{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supply Chain Optimization using MIS Demo\n",
    "---\n",
    "\n",
    "**NOTE: [Jump](#exec) to skip description:**\n",
    "\n",
    "The supply chain optimization problem can be formulated as a travel plan scheduling problem utilizing the power of TigerGraph Graph database in the following way.\n",
    "\n",
    "- There are a fixed number of trucks\n",
    "- Each travel plan is assigned a truck (not necessarily unique)\n",
    "- Number of trucks << Number of travel plans\n",
    "- There are a fixed number of work orders to be completed\n",
    "- Each travel plan is associated with one or more work orders\n",
    "- A work order might need more than 1 trip to be completed\n",
    "- Number of work orders << Number of travel plans\n",
    "\n",
    "Finally, the resource conflict is modelled as:\n",
    "\n",
    " - **If two travel plans share a truck or a work order, they can not be executed at the same time**\n",
    "\n",
    "### Problem Formulation\n",
    "\n",
    "In this example, the goal is to execute all travel plans in the least amount of time. To accomplish this, it can be stated that for a list of travel plans that are yet to be scheduled, we need to find the maximum number of travel plans that can be scheduled at the same time, given the set of available trucks and work orders to complete. When a set of scheduled travel plans are finished, the process is repeated until all travel plans are executed.\n",
    "\n",
    "Travel plans, trucks, work orders and their relationships can be easily captured by creating a TigerGraph graph database. Consider a scenario with 3 travel plans, 2 trucks and 2 work orders. The travel plans have dependencies on trucks and work orders as shown in the following figure:\n",
    "\n",
    "<img src=\"https://xilinx.github.io/graphanalytics/_images/mis-depen-graph.png\" width=200 height=200 />\n",
    "\n",
    "\n",
    "Truck tr0 is used in trips tp0 and tp2 while truck tr1 is used only in trip tp1. Similarly, work order wo0 is part of trips tp0 and tp1 while work order wo1 is split between trips tp1 and tp2. These dependencies create conflicts such that travel plans tp0 and tp2 can not be executed at the same time. This relationship is captured in a travel plans conflict graph as shown below where travel plans are represented as vertices and are connected by an edge if there is a schedule conflict between them.\n",
    "\n",
    "<img src=\"https://xilinx.github.io/graphanalytics/_images/mis-tp-graph.png\" width=140 height=140 />\n",
    "\n",
    "TigerGraph allows creation of the conflict graph easily by writing queries in GSQL. New edges are created in the original graph so that traversal can be done only on travel plan to travel plan edges while computing the MIS.\n",
    "\n",
    "### MIS Formulation\n",
    "\n",
    "After a conflict graph is obtained like above, the supply chain optimization problem can be modelled as an MIS problem on the conflict graph: Given the conflict graph of travel plans yet to be scheduled, find the MIS of the graph to obtain set of travel plans that can be scheduled at the same time. Execute the obtained MIS travel plans, remove vertices and edges associated to them from the conflict graph, and run MIS on the remaining sub-graph. This is continued till the graph is empty.\n",
    "\n",
    "If a maximal set is used instead of the maximum set, the scheduling will not be optimal. The Xilinx Maximal Independent Set library produces high “quality” (close to maximum) sets which can achieve close to optimal results for all practical purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next sections show how to create a TigerGraph Database and use the Xilinx Maximal Independent Set plugin to accelerate MIS computation.\n",
    "\n",
    "This notebook uses [pyTigerGraph](https://pytigergraph.github.io/pyTigerGraph/), a TigerGraph python interface to run gsql queries on a remote server running TigerGraph via Rest APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "---\n",
    "Boilerplate module imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from pathlib import Path, PurePosixPath\n",
    "import pyTigerGraph as tg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Login Setup\n",
    "Provide the remote TigerGraph server URL/IP address/hostname and credentials for a TigerGraph user. \n",
    "\n",
    "**NOTE**: The TigerGraph user should be created on the server side before proceeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hostName = \"localhost\"                              # TG server hostname\n",
    "userName = \"tigergraph\"                             # TG user name\n",
    "passWord = \"tigergraph\"                             # TG user password"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Path Setup\n",
    "**Local**: Location of query files under the Xilinx graphanalytics github repo. Set location of the local repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "localRepoLocation = Path(\"/opt/xilinx/apps\")\n",
    "exampleLocation = Path(\"graphanalytics/integration/Tigergraph-3.x/mis/0.2/examples/travelplan/\") # when running from github repo\n",
    "queryFileLocation = localRepoLocation / exampleLocation / \"query\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: Data files should exist on the TigerGraph server "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serverRepoLocation = PurePosixPath(\"/opt/xilinx/apps\")\n",
    "serverDataLocation = serverRepoLocation / PurePosixPath(exampleLocation) / \"data\"\n",
    "tp2woInfile = serverDataLocation / \"travelplan2workorders100.csv\"\n",
    "tp2trInfile = serverDataLocation / \"travelplan2trucks100.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Prepare TG database<a id=\"exec\"></a>\n",
    "Shows **one-time** preparation of the database. Once done, queries can be repeateadly run as shown in the next Section.\n",
    "1. [**Load Graph**](#loadg)\n",
    " - [Create new graph](#newg)\n",
    " - [Create graph schema](#schema)\n",
    " - [Load graph data](#loadd)\n",
    " - [Install queries](#install)\n",
    "\n",
    "\n",
    "2. [**Build Edges**](#build_edges)\n",
    "\n",
    "3. [**Generate CSR**](#csr)\n",
    "\n",
    "\n",
    "#### Run Queries on FPGA\n",
    "Shows **repeatable** use of query to run *accelerated* MIS on FPGA\n",
    "\n",
    "[**Compute MIS**](#run)\n",
    "1. [TigerGraph Native GSQL MIS](#tg_run)\n",
    "2. [Xilinx Alveo MIS](#alveo_run)\n",
    "\n",
    "The cells below show how to perform these steps in detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load Graph <a id=\"loadg\"></a>\n",
    "---\n",
    "#### 1.1 Create new graph <a id=\"newg\"></a>\n",
    "- Connect to TigerGraph server by ommiting graph name. This is needed to establish a valid REST endpoint that will be used to create a new desired graph\n",
    "- Create new graph by using gsql command and create a new connection with the new graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# connect to TG server and create graph\n",
    "graphName = f'travelplan_graph_{userName}'   # TG graph name\n",
    "conn = tg.TigerGraphConnection(host='http://' + hostName, graphname='', username=userName, password=passWord, useCert=False)\n",
    "print(\"\\n--------- Creating New graph ----------\")\n",
    "print(conn.gsql(f'create graph {graphName}()', options=[]))\n",
    "\n",
    "# connect to TG server with new graph\n",
    "print(f'Using graph {graphName}')\n",
    "conn = tg.TigerGraphConnection(host='http://' + hostName, graphname=graphName, username=userName, password=passWord, useCert=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any command or query will now run on the new graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Create graph schema <a id=\"schema\"></a>\n",
    "TigerGraph stores graph in the form of vertices that can be associated with other vertices using directed or undirected edges. This is specified in the form of a graph schema. For the purpose of this demo, the schema is already defined as a query file. Load the file, set graph name and run it as gsql commands. \n",
    "\n",
    "The user can create schema for their own graph in a similar way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--------- Creating New Schema ----------\")\n",
    "schemaFile = queryFileLocation / \"schema.gsql\"\n",
    "\n",
    "with open(schemaFile) as fh:\n",
    "    qStrRaw = fh.read()\n",
    "    qStr = qStrRaw.replace('@graph', graphName)\n",
    "    print(conn.gsql(qStr))\n",
    "print(\"\\n----------------- Done -----------------\")\n",
    "    \n",
    "# print a sneak peek of the schema\n",
    "schema = conn.getSchema(False)\n",
    "print(f\"\\nTotal {len(schema['VertexTypes'])} Vertices created:\")\n",
    "i = 1\n",
    "for v in schema['VertexTypes']:\n",
    "    print(f\" {i}. {v['Name']}\")\n",
    "    i+=1\n",
    "\n",
    "print(f\"\\nwith the following edges:\")\n",
    "i = 1\n",
    "for e in schema['EdgeTypes']:\n",
    "    print(f\" {i}. {e['Name']}: {e['FromVertexTypeName']} - {e['ToVertexTypeName']}\")\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Load graph data <a id=\"loadd\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--------- Loading data into graph ----------\")\n",
    "loadFile = queryFileLocation / \"load.gsql\"\n",
    "\n",
    "with open(loadFile) as fh:\n",
    "    qStrRaw = fh.read()\n",
    "    qStr = qStrRaw.replace('@graph', graphName)\n",
    "    print(conn.gsql(qStr))\n",
    "    print(conn.gsql(f'USE GRAPH {graphName}\\n RUN LOADING JOB load_tp2tr USING tp2tr_infile=\"{tp2trInfile}\"'))\n",
    "    print(conn.gsql(f\"USE GRAPH {graphName}\\n DROP JOB load_tp2tr\"))\n",
    "    print(conn.gsql(f'USE GRAPH {graphName}\\n RUN LOADING JOB load_tp2wo USING tp2wo_infile=\"{tp2woInfile}\"'))\n",
    "    print(conn.gsql(f\"USE GRAPH {graphName}\\n DROP JOB load_tp2wo\"))\n",
    "print(\"\\n------------------- Done -------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Install queries <a id=\"install\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--------- Installing Queries ----------\")\n",
    "queryFiles = [queryFileLocation / \"build_edges.gsql\",\n",
    "              queryFileLocation / \"tg_maximal_indep_set.gsql\",\n",
    "              queryFileLocation / \"xlnx_maximal_indep_set.gsql\"]\n",
    "\n",
    "for qf in queryFiles:\n",
    "    with open(qf) as fh:\n",
    "        print(f\"installing queries in {qf}...\")\n",
    "        qStrRaw = fh.read()\n",
    "        qStr = qStrRaw.replace('@graph', graphName)\n",
    "        print(conn.gsql(qStr))\n",
    "\n",
    "print(\"\\n--------- All queries installed ----------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graph Data Overview\n",
    " \n",
    "TigerGraph allows to check for some basic statistics about the graph in the following way:\n",
    "(Note: the edge and vertex functions return correct results only after the graph has had time to \"stabilize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Graph Statistics\n",
    "print(\"\\n--------- Graph Overview ----------\")\n",
    "total_vertices = conn.getVertexCount('*')\n",
    "print(f\"\\nTotal Vertices:\")\n",
    "for v in total_vertices:\n",
    "    print(f\"  {v}: {total_vertices[v]}\")\n",
    "\n",
    "print(f\"\\nTotal Edges:\")\n",
    "total_edges = conn.getEdgeCountFrom(edgeType='*')\n",
    "for e in total_edges:\n",
    "    print(f\"  {e}: {total_edges[e]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that queries are installed, rest of the operations can be performed simply by running the queries as follows.\n",
    "\n",
    "### 2. Build edges <a id=\"build_edges\"></a>\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "print('Building edges for travelplan vertices\\n'+'-'*38)\n",
    "tStart = time.perf_counter()\n",
    "result = conn.runInstalledQuery('build_edges', timeout=240000000)\n",
    "for res in result:\n",
    "    for k in res:\n",
    "            print(k, \":\", res[k])\n",
    "\n",
    "print('\\nWaiting for 20 sec for Graph changes to take effect!')\n",
    "total_edges = conn.getEdgeCountFrom(edgeType='*')\n",
    "print(f\"Number of tp2tp edges before wait: {total_edges['tp2tp']}\")\n",
    "time.sleep(30)\n",
    "print('Done!')\n",
    "total_edges = conn.getEdgeCountFrom(edgeType='*')\n",
    "print(f\"Number of tp2tp edges after wait: {total_edges['tp2tp']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Generate CSR <a id=\"csr\"></a>\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Assign unique IDs to Travel Plan vertices\\n'+'-'*41)\n",
    "result = conn.runInstalledQuery('assign_ids', {'v_type': \"travel_plan\", 'e_type': \"tp2tp\"}, timeout=240000000)\n",
    "for res in result:\n",
    "    for k in res:\n",
    "            print(k, \":\", res[k])\n",
    "            \n",
    "print('\\nBuild Row Ptr and Column Idx arrays\\n'+'-'*35)\n",
    "result = conn.runInstalledQuery('build_csr', {'v_type': \"travel_plan\", 'e_type': \"tp2tp\"}, timeout=240000000)\n",
    "for res in result:\n",
    "    for k in res:\n",
    "            print(k, \":\", res[k])\n",
    "\n",
    "print(f'\\ncompleted in {time.perf_counter() - tStart:.4f} sec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This completes the TigerGraph database preparation for MIS runs. We can now run as many MIS queries as we want. \n",
    "\n",
    "### Compute MIS <a id=\"run\"></a>\n",
    "---\n",
    "\n",
    "### 1. TigerGraph Native GSQL MIS: <a id=\"tg_run\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Running Queries on TG CPU\\n'+'-'*25)\n",
    "tStart = time.perf_counter()\n",
    "result = conn.runInstalledQuery('tg_maximal_indep_set',\n",
    "                                {'v_type': \"travel_plan\", 'e_type': \"tp2tp\", 'print_accum': True, 'file_path': \"\"},\n",
    "                                timeout=240000000)\n",
    "tDuration = 1000*(time.perf_counter() - tStart)\n",
    "\n",
    "for res in result:\n",
    "    for k in res:\n",
    "        if k == 'Start':\n",
    "            print(\"MIS :\", [x['v_id'] for x in res[k]])\n",
    "        else:\n",
    "            print(k, \":\", res[k])\n",
    "            \n",
    "    \n",
    "print(f\"\\nRound Trip time: {tDuration:.2f} msec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Xilinx Alveo MIS: <a id=\"alveo_run\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Running Queries on FPGA\\n'+'-'*23)\n",
    "tStart = time.perf_counter()\n",
    "result = conn.runInstalledQuery('maximal_indep_set_alveo',\n",
    "                                {'v_type': \"travel_plan\", 'e_type': \"tp2tp\", 'print_accum': True, 'file_path': \"\"},\n",
    "                                timeout=240000000)\n",
    "tDuration = 1000*(time.perf_counter() - tStart)\n",
    "\n",
    "for res in result:\n",
    "    for k in res:\n",
    "        if k == '@@mis':\n",
    "            print(\"MIS :\", res[k])\n",
    "        else:\n",
    "            print(k, \":\", res[k])\n",
    "    \n",
    "print(f\"\\nRound Trip time: {tDuration:.2f} msec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to play with the query!\n",
    "\n",
    "#### Thanks for your time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "312.6px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
