{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Travelplan Optimization using MIS Demo\n",
    "---\n",
    "This notebook uses [pyTigerGraph](https://pytigergraph.github.io/pyTigerGraph/), a TigerGraph python interface to run gsql queries on a remote server running TigerGraph via Rest APIs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "---\n",
    "Boilerplate module imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random as rand\n",
    "from pathlib import Path, PurePosixPath\n",
    "import pyTigerGraph as tg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Login Setup\n",
    "Provide the remote TigerGraph server URL/IP address/hostname and credentials for a TigerGraph user. \n",
    "\n",
    "**NOTE**: The TigerGraph user should be created on the server side before proceeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hostName = \"localhost\"                              # TG server hostname\n",
    "userName = \"tigergraph\"                             # TG user name\n",
    "passWord = \"Xilinx123\"                             # TG user password"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Path Setup\n",
    "**Local**: Location of query files under the Xilinx graphanalytics github repo. Set location of the local repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "localRepoLocation = Path(\"/opt/xilinx/apps\")\n",
    "exampleLocation = Path(\"graphanalytics/integration/Tigergraph-3.x/mis/0.2/examples/travelplan/\") # when running from github repo\n",
    "queryFileLocation = localRepoLocation / exampleLocation / \"query\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: Data should exist on the TigerGraph server "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "serverRepoLocation = PurePosixPath(\"/opt/xilinx/apps\")\n",
    "serverDataLocation = serverRepoLocation / PurePosixPath(exampleLocation) / \"data\"\n",
    "tp2woInfile = serverDataLocation / \"travelplan2workorders100.csv\"\n",
    "tp2trInfile = serverDataLocation / \"travelplan2trucks100.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Prepare TG database\n",
    "Shows **one-time** preparation of the database. Once done, queries can be repeateadly run as shown in the next Section.\n",
    "1. [**Load Graph**](#loadg)\n",
    " - [Create new graph](#newg)\n",
    " - [Create graph schema](#schema)\n",
    " - [Load graph data](#loadd)\n",
    " - [Install queries](#install)\n",
    "\n",
    "\n",
    "2. [**Build Edges**](#build_edges)\n",
    "\n",
    "\n",
    "#### Run Queries on FPGA\n",
    "Shows **repeatable** use of query to run *accelerated* MIS on FPGA\n",
    "1. [**Run MIS**](#run)\n",
    "\n",
    "The cells below show how to perform these steps in detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load Graph <a id=\"loadg\"></a>\n",
    "---\n",
    "#### 1.1 Create new graph <a id=\"newg\"></a>\n",
    "- Connect to TigerGraph server by ommiting graph name. This is needed to establish a valid REST endpoint that will be used to create a new desired graph\n",
    "- Create new graph by using gsql command and create a new connection with the new graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------- Creating New graph ----------\n",
      "The graph xgraph_tigergraph is created.\n",
      "Using graph xgraph_tigergraph\n"
     ]
    }
   ],
   "source": [
    "# connect to TG server and create graph\n",
    "graphName = f'xgraph_{userName}'   # TG graph name\n",
    "conn = tg.TigerGraphConnection(host='http://' + hostName, graphname='', username=userName, password=passWord, useCert=False)\n",
    "print(\"\\n--------- Creating New graph ----------\")\n",
    "print(conn.gsql(f'create graph {graphName}()', options=[]))\n",
    "\n",
    "# connect to TG server with new graph\n",
    "print(f'Using graph {graphName}')\n",
    "conn = tg.TigerGraphConnection(host='http://' + hostName, graphname=graphName, username=userName, password=passWord, useCert=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any command or query will now run on the new graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Create graph schema <a id=\"schema\"></a>\n",
    "TigerGraph stores graph in the form of vertices that can be associated with other vertices using directed or undirected edges. This is specified in the form of a graph schema. For the purpose of this demo, the schema is already defined as a query file. Load the file, set graph name and run it as gsql commands. \n",
    "\n",
    "The user can create schema for their own graph in a similar way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------- Creating New Schema ----------\n",
      "Using graph 'xgraph_tigergraph'\n",
      "The graph xgraph_tigergraph is dropped.\n",
      "The graph xgraph_tigergraph is created.\n",
      "The job job_schema_change_local is created.\n",
      "\n",
      "Current graph version 0\n",
      "Trying to add vertex travel_plan.\n",
      "Trying to add vertex work_order.\n",
      "Trying to add vertex truck.\n",
      "Trying to add edge tp2wo.\n",
      "Trying to add edge tp2truck.\n",
      "Trying to add edge tp2tp.\n",
      "Kick off job job_schema_change_local\n",
      "\n",
      "Graph xgraph_tigergraph update to new version 1\n",
      "The job job_schema_change_local completes in 10.632 seconds!\n",
      "The job job_schema_change_local is dropped!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--------- Creating New Schema ----------\")\n",
    "schemaFile = queryFileLocation / \"schema.gsql\"\n",
    "\n",
    "with open(schemaFile) as fh:\n",
    "    qStrRaw = fh.read()\n",
    "    qStr = qStrRaw.replace('@graph', graphName)\n",
    "    print(conn.gsql(qStr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Load graph data <a id=\"loadd\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------- Loading data into graph ----------\n",
      "Semantic Check Fails: The USING clause for the same file path \"null\" should be the same. However in Job 'load_xgraph' one block has USING clause as \"{SEPARATOR=,, USER_DEFINED_HEADER=tp2tr_header}\", while another block has USING clause as \"{SEPARATOR=,, USER_DEFINED_HEADER=tp2wo_header}\".\n",
      "Using graph 'xgraph_tigergraph'\n",
      "The job load_xgraph is created.\n",
      "\u001b[2A\n",
      "\u001b[2K\n",
      "\u001b[2K\n",
      "Using graph 'xgraph_tigergraph'\n",
      "[Tip: Use \"CTRL + C\" to stop displaying the loading status update, then use \"SHOW LOADING STATUS jobid\" to track the loading progress again]\n",
      "[Tip: Manage loading jobs with \"ABORT/RESUME LOADING JOB jobid\"]\n",
      "Starting the following job, i.e.\n",
      "JobName: load_xgraph, jobid: xgraph_tigergraph.load_xgraph.file.m1.1643956970716\n",
      "Loading log: '/home2/tigergraph/tigergraph/log/restpp/restpp_loader_logs/xgraph_tigergraph/xgraph_tigergraph.load_xgraph.file.m1.1643956970716.log'\n",
      "\n",
      "Job \"xgraph_tigergraph.load_xgraph.file.m1.1643956970716\" loading status\n",
      "[RUNNING] m1 ( Finished: 0 / Total: 2 )\n",
      "Job \"xgraph_tigergraph.load_xgraph.file.m1.1643956970716\" loading status\n",
      "[FINISHED] m1 ( Finished: 2 / Total: 2 )\n",
      "[LOADED]\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|                                                                                                                FILENAME |   LOADED LINES |   AVG SPEED |   DURATION|\n",
      "|    /opt/xilinx/apps/graphanalytics/integration/Tigergraph-3.x/mis/0.2/examples/travelplan/data/travelplan2trucks100.csv |            101 |     101 l/s |     1.00 s|\n",
      "|/opt/xilinx/apps/graphanalytics/integration/Tigergraph-3.x/mis/0.2/examples/travelplan/data/travelplan2workorders100.csv |            354 |     354 l/s |     1.00 s|\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "Using graph 'xgraph_tigergraph'\n",
      "The job load_xgraph is dropped!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--------- Loading data into graph ----------\")\n",
    "loadFile = queryFileLocation / \"load.gsql\"\n",
    "\n",
    "with open(loadFile) as fh:\n",
    "    qStrRaw = fh.read()\n",
    "    qStr = qStrRaw.replace('@graph', graphName)\n",
    "    print(conn.gsql(qStr))\n",
    "    print(conn.gsql(f'USE GRAPH {graphName}\\n RUN LOADING JOB load_xgraph USING tp2wo_infile=\"{tp2woInfile}\", tp2tr_infile=\"{tp2trInfile}\"'))\n",
    "    print(conn.gsql(f\"USE GRAPH {graphName}\\n DROP JOB load_xgraph\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Install queries <a id=\"install\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------- Installing Queries ----------\n",
      "installing queries in /opt/xilinx/apps/graphanalytics/integration/Tigergraph-3.x/mis/0.2/examples/travelplan/query/build_edges.gsql...\n",
      "Using graph 'xgraph_tigergraph'\n",
      "Query build_edges could not be found.\n",
      "The query build_edges has been added!\n",
      "Start installing queries, about 1 minute ...\n",
      "build_edges query: curl -X GET 'http://127.0.0.1:9000/query/xgraph_tigergraph/build_edges'. Add -H \"Authorization: Bearer TOKEN\" if authentication is enabled.\n",
      "\n",
      "installing queries in /opt/xilinx/apps/graphanalytics/integration/Tigergraph-3.x/mis/0.2/examples/travelplan/query/tg_maximal_indep_set.gsql...\n",
      "Query tg_maximal_indep_set could not be found.\n",
      "The query tg_maximal_indep_set has been added!\n",
      "Start installing queries, about 1 minute ...\n",
      "tg_maximal_indep_set query: curl -X GET 'http://127.0.0.1:9000/query/xgraph_tigergraph/tg_maximal_indep_set?v_type=VALUE&e_type=VALUE&[max_iter=VALUE]&[print_accum=VALUE]&[file_path=VALUE]'. Add -H \"Authorization: Bearer TOKEN\" if authentication is enabled.\n",
      "\n",
      "installing queries in /opt/xilinx/apps/graphanalytics/integration/Tigergraph-3.x/mis/0.2/examples/travelplan/query/xlnx_maximal_indep_set.gsql...\n",
      "Using graph 'xgraph_tigergraph'\n",
      "Query assign_ids could not be found.\n",
      "Query build_csr could not be found.\n",
      "Query maximal_indep_set_alveo could not be found.\n",
      "The query assign_ids has been added!\n",
      "The query build_csr has been added!\n",
      "The query maximal_indep_set_alveo has been added!\n",
      "Start installing queries, about 1 minute ...\n",
      "build_csr query: curl -X GET 'http://127.0.0.1:9000/query/xgraph_tigergraph/build_csr'. Add -H \"Authorization: Bearer TOKEN\" if authentication is enabled.\n",
      "assign_ids query: curl -X GET 'http://127.0.0.1:9000/query/xgraph_tigergraph/assign_ids'. Add -H \"Authorization: Bearer TOKEN\" if authentication is enabled.\n",
      "maximal_indep_set_alveo query: curl -X GET 'http://127.0.0.1:9000/query/xgraph_tigergraph/maximal_indep_set_alveo'. Add -H \"Authorization: Bearer TOKEN\" if authentication is enabled.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--------- Installing Queries ----------\")\n",
    "queryFiles = [queryFileLocation / \"build_edges.gsql\",\n",
    "              queryFileLocation / \"tg_maximal_indep_set.gsql\",\n",
    "              queryFileLocation / \"xlnx_maximal_indep_set.gsql\"]\n",
    "\n",
    "for qf in queryFiles:\n",
    "    with open(qf) as fh:\n",
    "        print(f\"installing queries in {qf}...\")\n",
    "        qStrRaw = fh.read()\n",
    "        qStr = qStrRaw.replace('@graph', graphName)\n",
    "        print(conn.gsql(qStr))\n",
    "\n",
    "print(\"\\n--------- All queries installed ----------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that queries are installed, rest of the operations can be performed simply by running the queries as follows.\n",
    "\n",
    "### 2. Build edges <a id=\"build_edges\"></a>\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building edges for travelplan vertices...\n",
      "completed in 0.0773 sec\n"
     ]
    }
   ],
   "source": [
    "print('Building edges for travelplan vertices...')\n",
    "tStart = time.perf_counter()\n",
    "conn.runInstalledQuery('build_edges', timeout=240000000)\n",
    "conn.runInstalledQuery('assign_ids', timeout=240000000)\n",
    "conn.runInstalledQuery('build_csr', timeout=240000000)\n",
    "print(f'completed in {time.perf_counter() - tStart:.4f} sec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This completes the TigerGraph database preparation for MIS runs. We can now run as many MIS queries as we want. \n",
    "\n",
    "### Compute MIS <a id=\"run\"></a>\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Queries on FPGA...\n",
      "ExecTimeInMs : 223.18157\n",
      "ComputationTechnique : Xilinx Alveo device\n",
      "PeakVirtualMemoryInGB : 2.65854\n",
      "PeakResidentMemoryInGB : 0.19234\n",
      "MisSize : 414\n",
      "\n",
      "Round Trip time: 234.01 msec\n"
     ]
    }
   ],
   "source": [
    "print('Running Queries on FPGA...')\n",
    "tStart = time.perf_counter()\n",
    "result = conn.runInstalledQuery('maximal_indep_set_alveo', timeout=240000000)\n",
    "tDuration = 1000*(time.perf_counter() - tStart)\n",
    "\n",
    "for res in result:\n",
    "    for k in res:\n",
    "        print(k, \":\", res[k])\n",
    "    \n",
    "print(f\"\\nRound Trip time: {tDuration:.2f} msec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to play with the query!\n",
    "\n",
    "#### Thanks for your time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "312.6px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
