{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to Parallel Compute Hackathon\n",
    "---\n",
    "This notebook uses [pyTigerGraph](https://pytigergraph.github.io/pyTigerGraph/), a TigerGraph python interface to calculate similarity using Xilinx FPGAs. The python package uses a Java client to run gsql queries on a remote server running TigerGraph via Rest APIs.\n",
    "\n",
    "#### The demo\n",
    "For the purpose of this demo, we will use medical data synthetically generated using an open-source tool called [Synthea](https://synthetichealth.github.io/synthea/) to find patients that are the most \"similar\" to a particular patient based on a list of attributes. The similarity score used is Cosine Similarity. For more information, refer to [Xilinx Alveo Graph Analytics](https://pages.gitenterprise.xilinx.com/FaaSApps/graphanalytics/index.html) doc. The demo is structured in two sections. Before proceeding, we configure the demo with the following setup steps.\n",
    " \n",
    "> **NOTE 1**: The synthea data is for demonstration purpose only and the user can use their own data and write queries to create their own embeddings.\n",
    "\n",
    "> **NOTE 2**: The TigerGraph plugin currently used to run queries on FPGA supports only one graph. Therefore, more than one concurrent users running this demo on the same TG server is not supported. This will be supported in a future version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "---\n",
    "Boilerplate module imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random as rand\n",
    "from pathlib import Path, PurePosixPath\n",
    "import pyTigerGraph as tg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Login Setup\n",
    "Provide the remote TigerGraph server URL/IP address/hostname and credentials for a TigerGraph user. \n",
    "\n",
    "**NOTE**: The TigerGraph user should be created on the server side before proceeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hostName = \"localhost\"                            # TG server hostname\n",
    "userName = \"dummy\"                                # TG user name\n",
    "passWord = \"password\"                             # TG user password"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demo variables\n",
    "Set variables to specify scale of the demo. Use these to: \n",
    "- set larger population sizes - the corresponding data for the population size should exist on the remote server\n",
    "- set number of best matching patients to return\n",
    "- set number of FPGAs to run the query on - larger number leads to larger acceleration but the TigerGraph server should have that many FPGA cards installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "populationSize = 1000                               # Size of the total patient population\n",
    "topK = 10                                           # Number of highest scoring patient matches\n",
    "numDevices = 1                                      # Number of FPGA devices to distribute the queries to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Path Setup\n",
    "**Local**: Location of query files under the Xilinx graphanalytics github repo. Set location of the local repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "localRepoLocation = Path(\"C:/Users/dummy\")\n",
    "exampleLocation = Path(\"graphanalytics/plugin/tigergraph/examples/synthea\") # when running from github repo\n",
    "queryFileLocation = localRepoLocation / exampleLocation / \"query\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remote**: Location of synthea generated data on the server. **NOTE**: Data should exist on the TigerGraph server "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serverRepoLocation = PurePosixPath(\"/home/dummy\")\n",
    "serverDataLocation = serverRepoLocation / PurePosixPath(exampleLocation) / \"1000_patients/csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPatient(id):\n",
    "    patientList = conn.getVerticesById('patients', id)\n",
    "    return [] if len(patientList) == 0 else patientList[0]\n",
    "\n",
    "def getPatientName(patient):\n",
    "    return patient['attributes']['FIRST_NAME'] + ' ' + patient['attributes']['LAST_NAME']\n",
    "\n",
    "def printResults(result, newPatient):\n",
    "    matches = result[0]['Matches']\n",
    "    print(f'Matches for patient {getPatientName(newPatient)}')\n",
    "    for m in matches:\n",
    "        matchingPatient = getPatient(m['Id'])\n",
    "        print(f'{m[\"score\"]} {getPatientName(matchingPatient)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Prepare TG database\n",
    "Shows **one-time** preparation of the database. Once done, queries can be repeateadly run as shown in the next Section.\n",
    "1. [**Load Graph**](#loadg)\n",
    " - [Create new graph](#newg)\n",
    " - [Create graph schema](#schema)\n",
    " - [Load graph data](#loadd)\n",
    " - [Install queries](#install)\n",
    "\n",
    "\n",
    "2. [**Create Embeddings**](#embed)\n",
    "3. [**Send Embeddings to FPGA**](#send)\n",
    "\n",
    "#### Run Queries on FPGA\n",
    "Shows **repeatable** use of query to run *accelerated* similarity computation on FPGA\n",
    "1. [**Compute Cosine Similarity**](#run)\n",
    "\n",
    "The cells below show how to perform these steps in detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load Graph <a id=\"loadg\"></a>\n",
    "---\n",
    "#### 1.1 Create new graph <a id=\"newg\"></a>\n",
    "- Connect to TigerGraph server by ommiting graph name. This is needed to establish a valid REST endpoint that will be used to create a new desired graph\n",
    "- Create new graph by using gsql command and create a new connection with the new graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# connect to TG server and create graph\n",
    "graphName = f'xgraph_{userName}_{populationSize}'   # TG graph name\n",
    "conn = tg.TigerGraphConnection(host='http://' + hostName, graphname='', username=userName, password=passWord, useCert=False)\n",
    "print(\"\\n--------- Creating New graph ----------\")\n",
    "print(conn.gsql(f'create graph {graphName}()', options=[]))\n",
    "\n",
    "# connect to TG server with new graph\n",
    "print(f'Using graph {graphName}')\n",
    "conn = tg.TigerGraphConnection(host='http://' + hostName, graphname=graphName, username=userName, password=passWord, useCert=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any command or query will now run on the new graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Create graph schema <a id=\"schema\"></a>\n",
    "TigerGraph stores graph in the form of vertices that can be associated with other vertices using directed or undirected edges. This is specified in the form of a graph schema. For the purpose of this demo, the schema is already defined as a query file. Load the file, set graph name and run it as gsql commands. \n",
    "\n",
    "The user can create schema for their own graph in a similar way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--------- Creating New Schema ----------\")\n",
    "schemaFile = queryFileLocation / \"schema_xgraph.gsql\"\n",
    "\n",
    "with open(schemaFile) as fh:\n",
    "    qStrRaw = fh.read()\n",
    "    qStr = qStrRaw.replace('@graph', graphName)\n",
    "    print(conn.gsql(qStr, options=[]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Load graph data <a id=\"loadd\"></a>\n",
    "The synthea data is split into files for each patient attribute (vertex in the schema). Each file is loaded and parsed. Open the load query file and, set graph name and location of the data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--------- Loading data into graph ----------\")\n",
    "loadFile = queryFileLocation / \"load_xgraph.gsql\"\n",
    "print(str(serverDataLocation))\n",
    "\n",
    "with open(loadFile) as fh:\n",
    "    qStrRaw = fh.read()\n",
    "    qStrRaw = qStrRaw.replace('@graph', graphName)\n",
    "    qStr    = qStrRaw.replace('$sys.data_root', str(serverDataLocation))\n",
    "    print(conn.gsql(qStr, options=[]))\n",
    "    print(conn.gsql(f\"RUN LOADING JOB load_xgraph\", options=['-g', graphName]))\n",
    "    print(conn.gsql(f\"DROP JOB load_xgraph\", options=['-g', graphName]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Install queries <a id=\"install\"></a>\n",
    "The cosine similarity application functionality is implemented using gsql queries and UDF functions. The queries need to be installed before running.\n",
    "\n",
    "The user can create their own queries and install them instead. If user writes their own UDFs, they will need to be compilled and opened as a TigerGraph Plugin (this is not covered in the scope of this demo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--------- Installing Queries ----------\")\n",
    "baseQFile = queryFileLocation / \"base.gsql\"\n",
    "clientQFile = queryFileLocation / \"client.gsql\"\n",
    "\n",
    "with open(baseQFile) as bfh, open(clientQFile) as cfh:\n",
    "    print(\"installing base queries ...\")\n",
    "    qStrRaw = bfh.read()\n",
    "    qStr = qStrRaw.replace('@graph', graphName)\n",
    "    print(conn.gsql(qStr, options=[]))\n",
    "    \n",
    "    print(\"\\ninstalling client queries ...\")\n",
    "    qStrRaw = cfh.read()\n",
    "    qStr = qStrRaw.replace('@graph', graphName)\n",
    "    print(conn.gsql(qStr, options=[]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that queries are installed, rest of the operations can be performed simply by running the queries as follows.\n",
    "\n",
    "### 2. Create Embeddings <a id=\"embed\"></a>\n",
    "---\n",
    "As seen earlier in the schema, each patient has a set of attributes which are represented as vertices. Additionaly, each patient is also represented as a vertex. The attributes of a patient are embedded into a vector representation called embeddings which are then stored as part of the patient vertex. Refer to [Cosine similarity](https://pages.gitenterprise.xilinx.com/FaaSApps/graphanalytics/overview.html#cosine-similarity) section for details on how the attributes are mapped to the patient embedding vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Creating patient embeddings and storing them in patient vertices...')\n",
    "tStart = time.perf_counter()\n",
    "conn.runInstalledQuery('client_cosinesim_embed_vectors', timeout=240000000)\n",
    "conn.runInstalledQuery('client_cosinesim_embed_normals', timeout=240000000)\n",
    "print(f'completed in {time.perf_counter() - tStart:.4f} sec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Send embeddings to FPGA <a id=\"send\"></a>\n",
    "---\n",
    "Finally, the embeddings are collected in a buffer which is sent/copied to HBM memory on the FPGA device. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading data into FPGA memory...')\n",
    "# set number of FPGAs to use\n",
    "conn.runInstalledQuery('client_cosinesim_set_num_devices', {'numDevices': numDevices}, timeout=240000000)\n",
    "\n",
    "# distribute data to FPGA memory\n",
    "tStart = time.perf_counter()\n",
    "resultHwLoad = conn.runInstalledQuery('client_cosinesim_load_alveo', timeout=240000000)\n",
    "print(f'completed in {time.perf_counter() - tStart:.4f} sec\\n')\n",
    "\n",
    "# Check status\n",
    "status = conn.runInstalledQuery('client_cosinesim_get_alveo_status', timeout=240000000)\n",
    "isInit = status[0][\"IsInitialized\"]\n",
    "numDev = status[0][\"NumDevices\"]\n",
    "print(f'FPGA Init: {isInit}, Dev: {numDev}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This completes the TigerGraph database and consine similiarity compute preparation. We can now run as many similarity queries as we want. \n",
    "\n",
    "### Compute Cosine Similarity <a id=\"run\"></a>\n",
    "---\n",
    "For the purpose of this demo, we get the first 100 patients and choose one at random. Patients are represented by an ID which is passed to the match query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Running Query...')\n",
    "# pick a random patient out of 100\n",
    "targetPatients = conn.getVertices('patients', limit=100)\n",
    "targetPatient = targetPatients[rand.randint(1,100)]\n",
    "\n",
    "# run similarity on the choosen patient\n",
    "tStart = time.perf_counter()\n",
    "result = conn.runInstalledQuery('client_cosinesim_match_alveo',\n",
    "                                  {'newPatient': targetPatient['v_id'], 'topK': topK}, timeout=240000000)\n",
    "tDuration = 1000*(time.perf_counter() - tStart)\n",
    "\n",
    "printResults(result, targetPatient)\n",
    "resTime = result[0][\"ExecTimeInMs\"]\n",
    "print(f\"\\nRound Trip time: {tDuration:.2f} msec\")\n",
    "print(f\"     Query time: {resTime:.2f} msec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that as a sanity check, the top matching patient is the query patient itself with a match score of 1.\n",
    "Feel free to play with the query!\n",
    "\n",
    "#### Thanks for your time!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "312.6px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
