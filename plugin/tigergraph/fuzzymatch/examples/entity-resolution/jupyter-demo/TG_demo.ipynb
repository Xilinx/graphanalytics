{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entity Resolution using FuzzyMatch Demo\n",
    "---\n",
    "This notebook uses [pyTigerGraph](https://pytigergraph.github.io/pyTigerGraph/), a TigerGraph python interface to run gsql queries on a remote server running TigerGraph via Rest APIs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "---\n",
    "Boilerplate module imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random as rand\n",
    "from pathlib import Path, PurePosixPath\n",
    "import pyTigerGraph as tg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Login Setup\n",
    "Provide the remote TigerGraph server URL/IP address/hostname and credentials for a TigerGraph user. \n",
    "\n",
    "**NOTE**: The TigerGraph user should be created on the server side before proceeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hostName = \"localhost\"                              # TG server hostname\n",
    "userName = \"tigergraph\"                             # TG user name\n",
    "passWord = \"Xilinx123\"                             # TG user password"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Path Setup\n",
    "**Local**: Location of query files under the Xilinx graphanalytics github repo. Set location of the local repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "localRepoLocation = Path(\"/opt/xilinx/apps\")\n",
    "exampleLocation = Path(\"graphanalytics/integration/Tigergraph-3.x/fuzzymatch/0.2/examples/entity-resolution\") # when running from github repo\n",
    "queryFileLocation = localRepoLocation / exampleLocation / \"query\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remote**: Location of input data on the server. **NOTE**: Data should exist on the TigerGraph server "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "serverRepoLocation = PurePosixPath(\"/opt/xilinx/apps\")\n",
    "serverDataLocation = serverRepoLocation / PurePosixPath(exampleLocation) / \"data\"\n",
    "ref_names_file = serverDataLocation / \"ref-names.csv\"\n",
    "new_names_file = serverDataLocation / \"new-names.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Prepare TG database\n",
    "Shows **one-time** preparation of the database. Once done, queries can be repeateadly run as shown in the next Section.\n",
    "1. [**Load Graph**](#loadg)\n",
    " - [Create new graph](#newg)\n",
    " - [Create graph schema](#schema)\n",
    " - [Load graph data](#loadd)\n",
    " - [Install queries](#install)\n",
    "\n",
    "\n",
    "#### Run Queries on FPGA\n",
    "Shows **repeatable** use of query to run *accelerated* similarity computation on FPGA\n",
    "1. [**Compute Fuzzy Match**](#run)\n",
    "\n",
    "The cells below show how to perform these steps in detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load Graph <a id=\"loadg\"></a>\n",
    "---\n",
    "#### 1.1 Create new graph <a id=\"newg\"></a>\n",
    "- Connect to TigerGraph server by ommiting graph name. This is needed to establish a valid REST endpoint that will be used to create a new desired graph\n",
    "- Create new graph by using gsql command and create a new connection with the new graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------- Creating New graph ----------\n",
      "The graph xgraph_tigergraph is created.\n",
      "Using graph xgraph_tigergraph\n"
     ]
    }
   ],
   "source": [
    "# connect to TG server and create graph\n",
    "graphName = f'xgraph_{userName}'   # TG graph name\n",
    "conn = tg.TigerGraphConnection(host='http://' + hostName, graphname='', username=userName, password=passWord, useCert=False)\n",
    "print(\"\\n--------- Creating New graph ----------\")\n",
    "print(conn.gsql(f'create graph {graphName}()', options=[]))\n",
    "\n",
    "# connect to TG server with new graph\n",
    "print(f'Using graph {graphName}')\n",
    "conn = tg.TigerGraphConnection(host='http://' + hostName, graphname=graphName, username=userName, password=passWord, useCert=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any command or query will now run on the new graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Create graph schema <a id=\"schema\"></a>\n",
    "TigerGraph stores graph in the form of vertices that can be associated with other vertices using directed or undirected edges. This is specified in the form of a graph schema. For the purpose of this demo, the schema is already defined as a query file. Load the file, set graph name and run it as gsql commands. \n",
    "\n",
    "The user can create schema for their own graph in a similar way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------- Creating New Schema ----------\n",
      "Using graph 'xgraph_tigergraph'\n",
      "The graph xgraph_tigergraph is dropped.\n",
      "The graph xgraph_tigergraph is created.\n",
      "The job job_schema_change_local is created.\n",
      "\n",
      "Current graph version 0\n",
      "Trying to add vertex ref_names.\n",
      "Trying to add vertex new_names.\n",
      "Trying to add vertex dummy_nodes.\n",
      "Kick off job job_schema_change_local\n",
      "\n",
      "Graph xgraph_tigergraph update to new version 1\n",
      "The job job_schema_change_local completes in 8.796 seconds!\n",
      "The job job_schema_change_local is dropped!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--------- Creating New Schema ----------\")\n",
    "schemaFile = queryFileLocation / \"schema.gsql\"\n",
    "\n",
    "with open(schemaFile) as fh:\n",
    "    qStrRaw = fh.read()\n",
    "    qStr = qStrRaw.replace('@graph', graphName)\n",
    "    print(conn.gsql(qStr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Load graph data <a id=\"loadd\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------- Loading data into graph ----------\n",
      "/opt/xilinx/apps/graphanalytics/integration/Tigergraph-3.x/fuzzymatch/0.2/examples/entity-resolution/data/ref-names.csv\n",
      "Using graph 'xgraph_tigergraph'\n",
      "The job load_job is created.\n",
      "\u001b[2A\n",
      "\u001b[2K\n",
      "\u001b[2K\n",
      "Using graph 'xgraph_tigergraph'\n",
      "[Tip: Use \"CTRL + C\" to stop displaying the loading status update, then use \"SHOW LOADING STATUS jobid\" to track the loading progress again]\n",
      "[Tip: Manage loading jobs with \"ABORT/RESUME LOADING JOB jobid\"]\n",
      "Starting the following job, i.e.\n",
      "JobName: load_job, jobid: xgraph_tigergraph.load_job.file.m1.1644967108827\n",
      "Loading log: '/home2/tigergraph/tigergraph/log/restpp/restpp_loader_logs/xgraph_tigergraph/xgraph_tigergraph.load_job.file.m1.1644967108827.log'\n",
      "\n",
      "Job \"xgraph_tigergraph.load_job.file.m1.1644967108827\" loading status\n",
      "[RUNNING] m1 ( Finished: 0 / Total: 2 )\n",
      "Job \"xgraph_tigergraph.load_job.file.m1.1644967108827\" loading status\n",
      "[FINISHED] m1 ( Finished: 2 / Total: 2 )\n",
      "[LOADED]\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|                                                                                                               FILENAME |   LOADED LINES |   AVG SPEED |   DURATION|\n",
      "|/opt/xilinx/apps/graphanalytics/integration/Tigergraph-3.x/fuzzymatch/0.2/examples/entity-resolution/data/new-names.csv |            260 |     259 l/s |     1.00 s|\n",
      "|/opt/xilinx/apps/graphanalytics/integration/Tigergraph-3.x/fuzzymatch/0.2/examples/entity-resolution/data/ref-names.csv |            843 |     842 l/s |     1.00 s|\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "Using graph 'xgraph_tigergraph'\n",
      "The job load_job is dropped!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--------- Loading data into graph ----------\")\n",
    "loadFile = queryFileLocation / \"load.gsql\"\n",
    "print(ref_names_file)\n",
    "with open(loadFile) as fh:\n",
    "    qStrRaw = fh.read()\n",
    "    qStr = qStrRaw.replace('@graph', graphName)\n",
    "    print(conn.gsql(qStr))\n",
    "    print(conn.gsql(f'USE GRAPH {graphName}\\n RUN LOADING JOB load_job USING ref_names_csv=\"{ref_names_file}\", new_names_csv=\"{new_names_file}\"'))\n",
    "    print(conn.gsql(f\"USE GRAPH {graphName}\\n DROP JOB load_job\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Install queries <a id=\"install\"></a>\n",
    "The cosine similarity application functionality is implemented using gsql queries and UDF functions. The queries need to be installed before running.\n",
    "\n",
    "The user can create their own queries and install them instead. If user writes their own UDFs, they will need to be compilled and opened as a TigerGraph Plugin (this is not covered in the scope of this demo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------- Installing Queries ----------\n",
      "installing base queries ...\n",
      "Using graph 'xgraph_tigergraph'\n",
      "The query insert_dummy_nodes is dropped.\n",
      "The query insert_dummy_nodes has been added!\n",
      "Start installing queries, about 1 minute ...\n",
      "insert_dummy_nodes query: curl -X GET 'http://127.0.0.1:9000/query/xgraph_tigergraph/insert_dummy_nodes?numNodes=VALUE'. Add -H \"Authorization: Bearer TOKEN\" if authentication is enabled.\n",
      "\n",
      "\n",
      "installing entity resolution queries ...\n",
      "Using graph 'xgraph_tigergraph'\n",
      "The query entity_resolution_tg is dropped.\n",
      "The query entity_resolution_alveo is dropped.\n",
      "The query entity_resolution_retres_alveo is dropped.\n",
      "The query entity_resolution_cpu is dropped.\n",
      "The query entity_resolution_tg has been added!\n",
      "The query entity_resolution_cpu has been added!\n",
      "The query entity_resolution_alveo has been added!\n",
      "The query entity_resolution_retres_alveo has been added!\n",
      "Start installing queries, about 1 minute ...\n",
      "entity_resolution_tg query: curl -X GET 'http://127.0.0.1:9000/query/xgraph_tigergraph/entity_resolution_tg'. Add -H \"Authorization: Bearer TOKEN\" if authentication is enabled.\n",
      "entity_resolution_alveo query: curl -X GET 'http://127.0.0.1:9000/query/xgraph_tigergraph/entity_resolution_alveo'. Add -H \"Authorization: Bearer TOKEN\" if authentication is enabled.\n",
      "entity_resolution_cpu query: curl -X GET 'http://127.0.0.1:9000/query/xgraph_tigergraph/entity_resolution_cpu'. Add -H \"Authorization: Bearer TOKEN\" if authentication is enabled.\n",
      "entity_resolution_retres_alveo query: curl -X GET 'http://127.0.0.1:9000/query/xgraph_tigergraph/entity_resolution_retres_alveo'. Add -H \"Authorization: Bearer TOKEN\" if authentication is enabled.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--------- Installing Queries ----------\")\n",
    "baseQFile = queryFileLocation / \"base.gsql\"\n",
    "clientQFile = queryFileLocation / \"entity_resolution.gsql\"\n",
    "\n",
    "with open(baseQFile) as bfh, open(clientQFile) as cfh:\n",
    "    print(\"installing base queries ...\")\n",
    "    qStrRaw = bfh.read()\n",
    "    qStr = qStrRaw.replace('@graph', graphName)\n",
    "    print(conn.gsql(qStr))\n",
    "    \n",
    "    print(\"\\ninstalling entity resolution queries ...\")\n",
    "    qStrRaw = cfh.read()\n",
    "    qStr = qStrRaw.replace('@graph', graphName)\n",
    "    print(conn.gsql(qStr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This completes the TigerGraph database and consine similiarity compute preparation. We can now run as many similarity queries as we want. \n",
    "\n",
    "### Compute FuzzyMatch <a id=\"run\"></a>\n",
    "---\n",
    "For the purpose of this demo, we get the first 100 patients and choose one at random. Patients are represented by an ID which is passed to the match query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Query on FPGA...\n",
      "ComputationTechnique : Xilinx Alveo device\n",
      "PeakVirtualMemoryInGB : 2.95938\n",
      "PeakResidentMemoryInGB : 0.44117\n",
      "RefNamesSize : 842\n",
      "TargetPersonsSize : 259\n",
      "MatchExecTimeInMs : 3\n",
      "AvergeTimePerPersonInMs : 0.01158\n",
      "\n",
      "Round Trip time: 51.88 msec\n"
     ]
    }
   ],
   "source": [
    "print('Running Query on FPGA...')\n",
    "\n",
    "tStart = time.perf_counter()\n",
    "result = conn.runInstalledQuery('entity_resolution_alveo', timeout=240000000)\n",
    "tDuration = 1000*(time.perf_counter() - tStart)\n",
    "\n",
    "for res in result:\n",
    "    for k in res:\n",
    "        print(k,\":\", res[k])\n",
    "\n",
    "print(f\"\\nRound Trip time: {tDuration:.2f} msec\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to play with the query!\n",
    "\n",
    "#### Thanks for your time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Query on CPU...\n",
      "ComputationTechnique : TigerGraph CPU\n",
      "PeakVirtualMemoryInGB : 2.98001\n",
      "PeakResidentMemoryInGB : 0.48928\n",
      "ExecTimeInMs : 63\n",
      "RefNamesSize : 842\n",
      "TargetPersonsSize : 259\n",
      "AvergeTimePerPersonInMs : 0.24324\n",
      "\n",
      "Round Trip time: 97.48 msec\n"
     ]
    }
   ],
   "source": [
    "print('Running Query on CPU...')\n",
    "\n",
    "tStart = time.perf_counter()\n",
    "result = conn.runInstalledQuery('entity_resolution_cpu', timeout=240000000)\n",
    "tDuration = 1000*(time.perf_counter() - tStart)\n",
    "\n",
    "for res in result:\n",
    "    for k in res:\n",
    "        print(k,\":\", res[k])\n",
    "\n",
    "print(f\"\\nRound Trip time: {tDuration:.2f} msec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "312.6px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
